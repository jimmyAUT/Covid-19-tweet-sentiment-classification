# Covid-19-tweet-sentiment-classification
## Introduction
Emploied three machine learning algorithms to perform a classification task on dataset text, namely 'covidtweet'. 
Naive Bayes, Neural Networks, and Convolutional Neural Networks (CNN). Naive Bayes is a probabilistic classifier suitable for tasks like text classification, operating under the assumption of feature independence. Neural Networks, inspired by the human brain, adaptively process data and can handle complex relationships in large datasets. CNNs, initially designed for image processing, can process text as one-dimensional 'images' and detect localized text patterns, making them effective for tasks like text classification and sentiment analysis.

## Data Description 
The COVID tweet training dataset provides insights into people's sentiments and reactions during the COVID outbreak from various locations. It comprises seven columns: UserName, ScreenName, Location, tweetAt, OriginalTweet, and Sentiment. UserName and ScreenName are integer identifiers unique to each user. All tweets are posted from 12,220 areas and on 30 different dates. Each tweet's content in the dataset is unique, leading to 41,157 unique values. Each data point has been labeled with one of five sentiments: neutral, positive, extremely positive, negative, and extremely negative.

## Text cleaning
For the Covid tweet dataset, given the informal language used in most tweets, which often includes abbreviations such as 'ain't,' 'won't,' 'he'd,' and so on, this report has introduced an abbreviation reduction dictionary. This dictionary aids in recognizing and converting these abbreviations into their formal equivalents. For example, 'ain’t' is transformed into 'am not / are not / is not / has not / have not,' and 'won’t' becomes 'will not,' 'he'd' can represent 'he had / he would,' and so forth. The dictionary is generated by chatGPT.
In the context of stop words, the report utilizes the nltk stopwords.words('english') list during the text cleaning process. However, this list may remove certain words, including some 'negative' and 'Degree Adverbs.' Given that the task involves classifying text into categories like 'positive,' 'negative,' 'neutral,' 'extremely positive,' and 'extremely negative,' words such as 'not,' 'no,' 'very,' 'many,' 'much,' etc., play a crucial role in distinguishing sentiment. Therefore, these words are retained. Additionally, social media language often incorporates symbols like '#' and '@' for labeling purposes, as well as embedded website addresses. This report primarily focuses on analyzing the content within the 'OriginalTweet' and excludes information related to locations, tweet dates, and user accounts. Consequently, these symbols are removed from consideration. The pre-processed data results in a token count reduction from 79,875 to 44,249.

In sentiment classification tasks, specific emotions may be associated with particular words, and TF-IDF vectorization can lead to information loss, resulting in a decrease in model training performance. Further preprocessing of pre-processed text data can also result in information loss and impact model performance. In contrast, appropriate preprocessing for raw, unprocessed text can enhance model training, although for CNNs, it may require two to three times the training epochs and time to achieve convergence, with only a 1% increase in the F1 score. If the model architecture is more complex, the cost increases significantly.
